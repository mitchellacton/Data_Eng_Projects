{
  "metadata": {
    "name": "Jarvis Hive Project",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Question 1: Load GS Data to HDFS\n#### Create new table location:\n    DROP TABLE IF EXISTS wdi_csv_text;\n    CREATE EXTERNAL TABLE wdi_csv_text\n    (year INTEGER, countryName STRING, countryCode STRING, indicatorName STRING, indicatorCode STRING, indicatorValue FLOAT)\n    ROW FORMAT DELIMITED FIELDS TERMINATED BY \u0027,\u0027 LINES TERMINATED BY \u0027\\n\u0027\n    LOCATION \u0027hdfs:///user/mitchellacton/hive/wdi/wdi_csv_text\u0027;\n\n#### Export data from google storage (GS) to HDFS:\n    INSERT OVERWRITE TABLE wdi_csv_text\n    SELECT * FROM wdi_gs;\n\n#### Count the rows:\n    SELECT count(countryName) FROM wdi_csv_text;\nThis query initially took 13.66 seconds to complete query. When run a second time, it took 4.77 seconds due to the data being stored in the file system\u0027s cache. After clearing the cache using the bash script `echo 3 | sudo tee /proc/sys/vm/drop_caches`, the query took 14.37 seconds.\n"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\nDROP TABLE IF EXISTS wdi_csv_text;\nCREATE EXTERNAL TABLE wdi_csv_text\n(year INTEGER, countryName STRING, countryCode STRING, indicatorName STRING, indicatorCode STRING, indicatorValue FLOAT)\nROW FORMAT DELIMITED FIELDS TERMINATED BY \u0027,\u0027 LINES TERMINATED BY \u0027\\n\u0027\nLOCATION \u0027hdfs:///user/mitchellacton/hive/wdi/wdi_csv_text\u0027;"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\nINSERT OVERWRITE TABLE wdi_csv_text\nSELECT * FROM wdi_gs;"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\nSELECT count(countryName) FROM wdi_csv_text;"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Question 2: Monitor Hadoop/Yarn Job\nBy viewing the Yarn Application Timeline, jobs performed by the cluster can be viewed. Details include the query ID, exit status, and which node executed the job. By using the TEZ UI, queries can be viewed graphically, and this is where execution times can be analyzed."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Question 3: Hive vs Bash\n#### Using bash to import and count the number of rows in the table\n    cd ~\n    hdfs  dfs -get  hdfs:///user/mitchellacton/hive/wdi/wdi_csv_text .\n    cd wdi_csv_text\n    echo 3 | sudo tee /proc/sys/vm/drop_caches\n    date +%s \u0026\u0026 cat * | wc \u0026\u0026 date +%s\n\nThis Query took 29 seconds, compared to 14 seconds with hive"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh\ncd ~\nhdfs  dfs -get  hdfs:///user/mitchellacton/hive/wdi/wdi_csv_text .\ncd wdi_csv_text\necho 3 | sudo tee /proc/sys/vm/drop_caches\ndate +%s \u0026\u0026 cat * | wc \u0026\u0026 date +%s"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Question 4: Parsing Issue\n#### What is the problem?\n    SELECT distinct(indicatorcode)\n    FROM wdi_csv_text\n    ORDER BY indicatorcode\n    LIMIT 20;\nIt seems like there are some incorrect values in the indicatorcode column. To further investigate, I will make a debug table below containing one column with all values for each row, with no comma delimiting.\n\n#### Debug Table\n    DROP TABLE IF EXISTS wdi_gs_debug;\n    CREATE EXTERNAL TABLE wdi_gs_debug\n    (line String)\n    ROW FORMAT DELIMITED LINES TERMINATED BY \u0027\\n\u0027\n    LOCATION \u0027gs://jarvis_data_eng_mitchellacton/datasets/wdi_2016\u0027;\n#### Querying the Debug Table\n    SELECT * FROM wdi_gs_debug\n    WHERE line like \"%\\(\\% of urban population\\)%\"\n    LIMIT 20;\nNow we can see that some entries in the fourth column, indicatorName, contain commas which are being parsed incorrectly as the end of the field, and the second half of the indicatorName is being assigned to the indicatorCode field. I will make a new table using different parsing to correct this.\n#### Fixing the issue in GS\n    DROP TABLE IF EXISTS wdi_opencsv_gs;\n    CREATE EXTERNAL TABLE wdi_opencsv_gs\n    (year INTEGER, countryName STRING, countryCode STRING, indicatorName STRING, indicatorCode STRING, indicatorValue FLOAT)\n    ROW FORMAT SERDE \u0027org.apache.hadoop.hive.serde2.OpenCSVSerde\u0027\n    STORED AS TEXTFILE\n    LOCATION \u0027gs://jarvis_data_eng_mitchellacton/datasets/wdi_2016\u0027;\n#### Fixing the issue in HDFS\n    DROP TABLE IF EXISTS wdi_opencsv_text;\n    CREATE EXTERNAL TABLE wdi_opencsv_text\n    (year INTEGER, countryName STRING, countryCode STRING, indicatorName STRING, indicatorCode STRING, indicatorValue FLOAT)\n    ROW FORMAT SERDE \u0027org.apache.hadoop.hive.serde2.OpenCSVSerde\u0027\n    STORED AS TEXTFILE\n    LOCATION \u0027hdfs:///user/mitchellacton/hive/wdi/wdi_opencsv_text\u0027;\n#### Checking the new table\n    SELECT distinct(indicatorcode) FROM wdi_opencsv_text\n    LIMIT 20;\nThe query shows that the indicator codes are now displayed correctly, however there is a significant increase in execution time from 15.00 seconds to 81.55 seconds when querying wdi_opencsv_text using the below queries. This is mostly due to the more complex parsing going on behind the scenes. Instead of using the LazySimpleSerDe parser, the OpenCSVSerDe parser is used.\n#### Testing execution times\n    SELECT count(countryName) FROM wdi_csv_text;\n    SELECT count(countryName) FROM wdi_opencsv_text;\n\n\n\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\nSELECT distinct(indicatorcode)\nFROM wdi_csv_text\nORDER BY indicatorcode\nLIMIT 20;\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### What\u0027s the Problem?\nIt seems like there are some incorrect values in the indicatorcode column. To further investigate, I will make a debug table below containing one column containing all values for each row, with no comma delimiting."
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\nDROP TABLE IF EXISTS wdi_gs_debug;\nCREATE EXTERNAL TABLE wdi_gs_debug\n(line String)\nROW FORMAT DELIMITED LINES TERMINATED BY \u0027\\n\u0027\nLOCATION \u0027gs://jarvis_data_eng_mitchellacton/datasets/wdi_2016\u0027;\n\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\nSELECT * FROM wdi_gs_debug\nWHERE line like \"%\\(\\% of urban population\\)%\"\nLIMIT 20;"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\nDROP TABLE IF EXISTS wdi_opencsv_gs;\nCREATE EXTERNAL TABLE wdi_opencsv_gs\n(year INTEGER, countryName STRING, countryCode STRING, indicatorName STRING, indicatorCode STRING, indicatorValue FLOAT)\nROW FORMAT SERDE \u0027org.apache.hadoop.hive.serde2.OpenCSVSerde\u0027\nSTORED AS TEXTFILE\nLOCATION \u0027gs://jarvis_data_eng_mitchellacton/datasets/wdi_2016\u0027;"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\nDROP TABLE IF EXISTS wdi_opencsv_text;\nCREATE EXTERNAL TABLE wdi_opencsv_text\n(year INTEGER, countryName STRING, countryCode STRING, indicatorName STRING, indicatorCode STRING, indicatorValue FLOAT)\nROW FORMAT SERDE \u0027org.apache.hadoop.hive.serde2.OpenCSVSerde\u0027\nSTORED AS TEXTFILE\nLOCATION \u0027hdfs:///user/mitchellacton/hive/wdi/wdi_opencsv_text\u0027;"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\nINSERT OVERWRITE TABLE wdi_opencsv_text\nSELECT * FROM wdi_opencsv_gs;"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\nSELECT distinct(indicatorcode) FROM wdi_opencsv_text\nLIMIT 20;"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\nSELECT count(countryName) FROM wdi_opencsv_text;\n"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\nSELECT count(countryName) FROM wdi_csv_text"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Question 5: OpenCSVSerDe Limitation\n#### Table metadata using different parsers\n    DESCRIBE FORMATTED wdi_csv_text;\n    DESCRIBE FORMATTED wdi_opencsv_text;\nAll data types in the `wdi_opencsv_text` table are strings, where in the `wdi_csv_text` table the year is `int` type and the indicatorvalue is `float` type. I will cast these fields to the correct type, and check the data types again to confirm.\n\n#### Casting column types\n    DROP VIEW IF EXISTS wdi_opencsv_text_view;\n    CREATE VIEW wdi_opencsv_text_view AS\n    SELECT CAST(year AS INTEGER) , countryName, countryCode, indicatorName, indicatorCode, CAST(indicatorValue AS FLOAT)\n    FROM wdi_opencsv_text;\n    DESCRIBE FORMATTED wdi_opencsv_text_view;\nThis has resolved the issue, and the `year` and `indicatorvalue` columns are now listed as `int` and `float` types respectively\n"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\nDESCRIBE FORMATTED wdi_csv_text;"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\nDESCRIBE FORMATTED wdi_opencsv_text;"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\nDROP VIEW IF EXISTS wdi_opencsv_text_view;\nCREATE VIEW wdi_opencsv_text_view AS\nSELECT CAST(year AS INTEGER) , countryName, countryCode, indicatorName, indicatorCode, CAST(indicatorValue AS FLOAT)\nFROM wdi_opencsv_text;\nDESCRIBE FORMATTED wdi_opencsv_text_view;\n\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Question 6: 2015 Canada GDP Growth HQL\nIn this section I will write queries to find the annual Canadian GDP growth for 2015.\n\n#### Find GDP growth `indicatorCode`\n    SELECT countryname, indicatorname, indicatorcode\n    FROM wdi_opencsv_text\n    WHERE UPPER(countryName)\u003d \"CANADA\" and UPPER(indicatorname) LIKE \"%GDP%\"\n    LIMIT 200;\nThe `indicatorCode` corresponding to GDP Growth is \"NY.GDP.MKTP.KD.ZG\"\n#### Find Canada\u0027s GDP growth for 2015\n    SELECT countryname, indicatorname, year, indicatorvalue\n    FROM wdi_opencsv_text\n    WHERE UPPER(countryname)\u003d\"CANADA\" and indicatorcode\u003d\"NY.GDP.MKTP.KD.ZG\" and year\u003d\"2015\";\nIn 2015, Canada\u0027s GDP grew by 1.078%, but this query took 85.66 seconds to get that information, because all 21 million rows need to be searched O(n). To reduce the execution time, the table could be partitioned (e.g. into smaller tables that  contain data for each year) or made faster via indexing using a BST. This would reduce the search time to O(logn), or log(21million), roughly 24 operations (almost a million times faster).\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\nSELECT countryname, indicatorname, indicatorcode\nFROM wdi_opencsv_text\nWHERE UPPER(countryName)\u003d \"CANADA\" and UPPER(indicatorname) LIKE \"%GDP%\"\nLIMIT 200;"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\nSELECT countryname, indicatorname, year, indicatorvalue\nFROM wdi_opencsv_text\nWHERE UPPER(countryname)\u003d\"CANADA\" and indicatorcode\u003d\"NY.GDP.MKTP.KD.ZG\" and year\u003d\"2015\";"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Question 7: Hive Partitions\nIn this section I will be optimizing the query speed by partitioning the table\n#### Create partitioned table\n    DROP TABLE IF EXISTS wdi_opencsv_text_partitions;\n    CREATE EXTERNAL TABLE wdi_opencsv_text_partitions\n    (countryName STRING, countryCode STRING, indicatorName STRING, indicatorCode STRING, indicatorValue STRING)\n    PARTITIONED BY (year STRING)\n    ROW FORMAT SERDE \u0027org.apache.hadoop.hive.serde2.OpenCSVSerde\u0027\n    STORED AS TEXTFILE\n    LOCATION \u0027hdfs:///user/mitchellacton/hive/wdi/wdi_opencsv_text_partitions\u0027;\n#### Populate partitioned table\n    SET hive.exec.dynamic.partition.mode\u003dnonstrict;\n    Set hive.exec.max.dynamic.partitions.pernode\u003d100;\n    FROM wdi_opencsv_text\n    INSERT OVERWRITE TABLE wdi_opencsv_text_partitions PARTITION(year)\n    SELECT countryname, countrycode, indicatorname, indicatorcode, indicatorvalue, year;\nThe `Set hive.exec.max.dynamic.partitions.pernode\u003d100` command sets the maximum number of partitions created by hive for this node. The default value is 100, but this can be increased if needed. 100 is more than enough for this case.\n#### Determine the number of partitions\n    hdfs dfs -count -h /user/mitchellacton/hive/wdi/wdi_opencsv_text_partitions\nBy counting the number of subdirectories, this bash command revealed that 59 partitions were created\n#### Find Canada\u0027s GDP for 2015 in partitioned table\n    SELECT countryname, indicatorname, year, indicatorvalue\n    FROM wdi_opencsv_text_partitions\n    WHERE UPPER(countryname)\u003d\"CANADA\" and indicatorcode\u003d\"NY.GDP.MKTP.KD.ZG\" and year\u003d\"2015\";\nThis time, the query took only 26 seconds instead of 85\n"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\nDROP TABLE IF EXISTS wdi_opencsv_text_partitions;\nCREATE EXTERNAL TABLE wdi_opencsv_text_partitions\n(countryName STRING, countryCode STRING, indicatorName STRING, indicatorCode STRING, indicatorValue STRING)\nPARTITIONED BY (year STRING)\nROW FORMAT SERDE \u0027org.apache.hadoop.hive.serde2.OpenCSVSerde\u0027\nSTORED AS TEXTFILE\nLOCATION \u0027hdfs:///user/mitchellacton/hive/wdi/wdi_opencsv_text_partitions\u0027;\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\nSET hive.exec.dynamic.partition.mode\u003dnonstrict;\nSet hive.exec.max.dynamic.partitions.pernode\u003d100;\nFROM wdi_opencsv_text\nINSERT OVERWRITE TABLE wdi_opencsv_text_partitions PARTITION(year)\nSELECT countryname, countrycode, indicatorname, indicatorcode, indicatorvalue, year;\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\nSELECT countryname, indicatorname, year, indicatorvalue\nFROM wdi_opencsv_text_partitions\nWHERE UPPER(countryname)\u003d\"CANADA\" and indicatorcode\u003d\"NY.GDP.MKTP.KD.ZG\" and year\u003d\"2015\";"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Question 8: Columnar File Optimization\n#### Store the data in Parquet format\n    DROP TABLE IF EXISTS wdi_csv_parquet;\n    CREATE EXTERNAL TABLE wdi_csv_parquet\n    (year INTEGER, countryName STRING, countryCode STRING, indicatorName STRING, indicatorCode STRING, indicatorValue FLOAT)\n    STORED AS PARQUET\n    LOCATION \u0027hdfs:///user/mitchellacton/hive/wdi/wdi_csv_parquet\u0027;\n    \n    INSERT OVERWRITE TABLE wdi_csv_parquet\n    SELECT * FROM wdi_opencsv_gs;\n#### Compare file sizes of Parquet and Text tables\n    hdfs dfs -du -s -h /user/mitchellacton/hive/wdi/wdi_opencsv_text\n    hdfs dfs -du -s -h /user/mitchellacton/hive/wdi/wdi_csv_parquet\n`wdi_opencsv_text`: 2.3 GB\n`wdi_csv_parquet`: 137.2 MB\n#### Compare runtime when counting rows\n    SELECT count(countryname) FROM wdi_opencsv_text;\n    SELECT count(countryname) FROM wdi_csv_parquet;\nRunning the query took 81 seconds on the text table, and only 6 seconds on the parquet table.\n#### Compare runtime for the GDP query\n    SELECT countryname, indicatorname, year, indicatorvalue\n    FROM wdi_csv_parquet\n    WHERE UPPER(countryname)\u003d\"CANADA\" and indicatorcode\u003d\"NY.GDP.MKTP.KD.ZG\" and year\u003d\"2015\";\nThis query took 34 seconds on the parquet table, compared to 86 seconds on the text table\n\n    "
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\nDROP TABLE IF EXISTS wdi_csv_parquet;\nCREATE EXTERNAL TABLE wdi_csv_parquet\n(year INTEGER, countryName STRING, countryCode STRING, indicatorName STRING, indicatorCode STRING, indicatorValue FLOAT)\nSTORED AS PARQUET\nLOCATION \u0027hdfs:///user/mitchellacton/hive/wdi/wdi_csv_parquet\u0027;"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\nINSERT OVERWRITE TABLE wdi_csv_parquet\nSELECT * FROM wdi_opencsv_gs;"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\nSELECT count(countryname) FROM wdi_opencsv_text;\nSELECT count(countryname) FROM wdi_csv_parquet;\n"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\nSELECT countryname, indicatorname, year, indicatorvalue\nFROM wdi_csv_parquet\nWHERE UPPER(countryname)\u003d\"CANADA\" and indicatorcode\u003d\"NY.GDP.MKTP.KD.ZG\" and year\u003d\"2015\";"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Question 9: Highest GDP Growth\n#### Display the highest GDP growth year for each country\n    SELECT table1.countryname, table1.year, table1.indicatorvalue\n    FROM wdi_csv_parquet table1\n    INNER JOIN (\n    SELECT countryname, MAX(indicatorvalue) AS maxGDP\n    FROM wdi_csv_parquet\n    WHERE indicatorcode\u003d\"NY.GDP.MKTP.KD.ZG\" AND indicatorvalue \u003c\u003e 0\n    GROUP BY countryname\n    ) table2\n    ON table1.indicatorvalue\u003dtable2.maxGDP AND table1.countryname \u003d table2.countryname\n    ORDER BY table1.countryname;\nBy joining the table\u0027s countryname, year, and indicatorvalue columns with the maximum indicatorvalue for GDP, the query will show the highest GDP growth year for each country. The same query was run using tez and spark, tez took 98 seconds while spark only took 53 seconds.\n"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\nSELECT table1.countryname, table1.year, table1.indicatorvalue\nFROM wdi_csv_parquet table1\nINNER JOIN (\nSELECT countryname, MAX(indicatorvalue) AS maxGDP\nFROM wdi_csv_parquet\nWHERE indicatorcode\u003d\"NY.GDP.MKTP.KD.ZG\" AND indicatorvalue \u003c\u003e 0\nGROUP BY countryname\n) table2\nON table1.indicatorvalue\u003dtable2.maxGDP AND table1.countryname \u003d table2.countryname\nORDER BY table1.countryname;\n\n\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%spark.sql\nSELECT table1.countryname, table1.year, table1.indicatorvalue\nFROM wdi_csv_parquet table1\nINNER JOIN (\nSELECT countryname, MAX(indicatorvalue) AS maxGDP\nFROM wdi_csv_parquet\nWHERE indicatorcode\u003d\"NY.GDP.MKTP.KD.ZG\" AND indicatorvalue \u003c\u003e 0\nGROUP BY countryname\n) table2\nON table1.indicatorvalue\u003dtable2.maxGDP AND table1.countryname \u003d table2.countryname\nORDER BY table1.countryname;\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Question 10: Sort GDP by country and year\n    SELECT countryname, year, indicatorvalue AS GDP_Growth\n    FROM wdi_csv_parquet\n    WHERE indicatorcode\u003d\"NY.GDP.MKTP.KD.ZG\"\n    ORDER BY countryname, year;"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%hive\nSELECT countryname, year, indicatorvalue AS GDP_Growth\nFROM wdi_csv_parquet\nWHERE indicatorcode\u003d\"NY.GDP.MKTP.KD.ZG\"\nORDER BY countryname, year;\n"
    }
  ]
}